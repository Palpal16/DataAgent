{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ff2875e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Colab smoke test: load this repo and import your modules\n",
        "# Option A (recommended): clone your GitHub repo\n",
        "#   1) Set REPO_URL to your repository URL\n",
        "#   2) Run this cell\n",
        "\n",
        "REPO_URL = \"https://github.com/<user>/<repo>.git\"  # TODO: replace\n",
        "REPO_DIR = \"DataAgent\"  # folder name after clone (adjust if different)\n",
        "\n",
        "import os, sys\n",
        "\n",
        "# If you're running this notebook *inside the repo already* (e.g., Drive mount),\n",
        "# set REPO_URL = \"\" and set REPO_DIR = \"/content/drive/MyDrive/<path>/DataAgent\".\n",
        "\n",
        "if REPO_URL:\n",
        "    !git clone -q {REPO_URL} {REPO_DIR}\n",
        "\n",
        "%cd {REPO_DIR}\n",
        "\n",
        "# Install dependencies\n",
        "!pip -q install -r requirements.txt\n",
        "\n",
        "# Make repo importable\n",
        "sys.path.insert(0, os.getcwd())\n",
        "\n",
        "print(\"Repo cwd:\", os.getcwd())\n",
        "print(\"sys.path[0]:\", sys.path[0])\n",
        "\n",
        "# Smoke-test imports (no model call yet)\n",
        "import Agent\n",
        "from Agent import data_agent\n",
        "from Agent.data_agent import SalesDataAgent\n",
        "\n",
        "print(\"Imported OK\")\n",
        "print(\"Agent package:\", Agent.__file__)\n",
        "print(\"SalesDataAgent:\", SalesDataAgent)\n",
        "\n",
        "# Optional: check LangGraph import (used by the agent)\n",
        "import langgraph\n",
        "print(\"langgraph:\", getattr(langgraph, \"__version__\", \"(no __version__)\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4275338b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# If you want to *run* the agent in Colab, you need an LLM backend accessible from Colab.\n",
        "# Ollama is local to your PC, so it won't work in Colab unless you expose it.\n",
        "#\n",
        "# Example placeholder (will fail unless you configure a remote backend):\n",
        "# agent = SalesDataAgent(model=\"llama3.2:3b\", ollama_url=\"http://localhost:11434\")\n",
        "# agent.run(\"What is the total sales in october 2022?\", no_vis=True, save_dir=\"./output_colab\")\n",
        "\n",
        "print(\"Import test complete. Configure an LLM backend to run the agent.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1fad738",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run a YAML experiment in Colab (like you do locally)\n",
        "# This builds the Linux C++ runner, then runs it with a Colab-safe YAML copy.\n",
        "\n",
        "# 1) Pick which YAML you want to run\n",
        "CONFIG_PATH = \"config/agent_config.yaml\"  # or \"config/agent_config_exp1_bestof_sweep.yaml\"\n",
        "\n",
        "# 2) Install build tools + YAML parser\n",
        "!apt-get -qq update\n",
        "!apt-get -qq install -y build-essential cmake\n",
        "!pip -q install pyyaml\n",
        "\n",
        "# (Optional) Check Java availability (needed for SPICE)\n",
        "!java -version\n",
        "\n",
        "# 3) Build the C++ runner for Linux (Colab)\n",
        "!cmake -S my_cpp -B my_cpp/build-colab -DCMAKE_BUILD_TYPE=Release\n",
        "!cmake --build my_cpp/build-colab --target agent_config_runner -j 2\n",
        "\n",
        "# 4) Create a Colab-safe YAML copy (so you don't need to edit your repo YAML)\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "cfg = yaml.safe_load(Path(CONFIG_PATH).read_text(encoding=\"utf-8\"))\n",
        "\n",
        "# Colab uses linux python\n",
        "cfg[\"python_bin\"] = \"python3\"\n",
        "\n",
        "# IMPORTANT: Ollama runs on your local PC, so it won't be reachable from Colab.\n",
        "# If you keep Ollama, this will fail unless you provide a reachable ollama_url.\n",
        "# Example (ONLY if you have a public endpoint / tunnel):\n",
        "# cfg[\"ollama_url\"] = \"http://<public-host>:11434\"\n",
        "\n",
        "# SPICE: point the YAML-copy to a jar inside the repo if available.\n",
        "# Recommended: include the folder SPICE-1.0/ in your repo or place it in the Colab workspace.\n",
        "spice_jar = Path(\"SPICE-1.0/spice-1.0.jar\")\n",
        "if spice_jar.exists():\n",
        "    cfg.setdefault(\"spice\", {})\n",
        "    cfg[\"spice\"][\"jar_path\"] = str(spice_jar)\n",
        "    cfg[\"spice\"][\"java_bin\"] = \"java\"\n",
        "    print(\"Using SPICE jar:\", spice_jar)\n",
        "else:\n",
        "    print(\"SPICE jar not found at\", spice_jar)\n",
        "    print(\"Place it at SPICE-1.0/spice-1.0.jar (e.g., add to repo or download in Colab).\")\n",
        "\n",
        "# If you just want to test the runner wiring without model calls, set sweep.enabled=false and run_batch=false,\n",
        "# then use a very small prompt and expect the LLM call to be the only blocker.\n",
        "\n",
        "tmp_yaml = Path(\"/content/agent_config_colab.yaml\")\n",
        "with tmp_yaml.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    yaml.safe_dump(cfg, f, sort_keys=False)\n",
        "\n",
        "print(\"Wrote:\", tmp_yaml)\n",
        "\n",
        "# 5) Run the YAML via the runner\n",
        "!./my_cpp/build-colab/agent_config_runner {tmp_yaml}\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
